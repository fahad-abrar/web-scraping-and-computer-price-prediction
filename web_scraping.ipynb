{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for scraping product link\n",
    "def scrape_product_links(url, max_links):\n",
    "    product_links = []\n",
    "    page = 1\n",
    "    while len(product_links) < max_links:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url.format(page))\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find all product links with class 'product-item-link'\n",
    "        all_links = soup.find('div', class_='main-products product-grid').find_all('div', class_= 'name')\n",
    "        # Extract product links\n",
    "        for link in all_links:\n",
    "            product_links.append(link.find('a')['href'])\n",
    "            if len(product_links) == max_links:\n",
    "                break\n",
    "        # Check if there are more pages\n",
    "        next_page_link = soup.find('a', class_='next')\n",
    "        if next_page_link:\n",
    "            page = page + 1\n",
    "            url = next_page_link['href']\n",
    "        else:\n",
    "            break\n",
    "    return product_links\n",
    "test_url= 'https://www.techlandbd.com/shop-laptop-computer/brand-laptops?page={}'\n",
    "# test the fuction for checking it works welproduct_links = scrape_product_links(test_url, 5)\n",
    "\n",
    "product_links = scrape_product_links(test_url, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.techlandbd.com/hp-pavilion-15-eg2117tu-laptop',\n",
       " 'https://www.techlandbd.com/asus-tuf-gaming-a15-fa507rm-jaeger-gray',\n",
       " 'https://www.techlandbd.com/asus-rog-strix-g15-g513rm-gaming-laptop',\n",
       " 'https://www.techlandbd.com/asus-tuf-gaming-a15-fa507re-laptop-jaeger-gray',\n",
       " 'https://www.techlandbd.com/asus-tuf-gaming-a15-fa506qm-156-r7-laptop']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WCS\\AppData\\Local\\Temp\\ipykernel_4252\\2745914883.py:22: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  if tbody.find_all('td', class_='attribute-name', text='Dimension'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural silver\n",
      "Jaeger Gray\n",
      "Eclipse Grey\n",
      "JAEGER GRAY / MECHA GRAY\n",
      "Graphite Black\n"
     ]
    }
   ],
   "source": [
    "brand = []\n",
    "product_model = []\n",
    "processor = []\n",
    "graphics = []\n",
    "memory = []\n",
    "storage = []\n",
    "display = []\n",
    "warranty = []\n",
    "price = []\n",
    "\n",
    "\n",
    "for link in product_links:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('div', class_='table-responsive')\n",
    "    tbodis = table.find_all('tbody')\n",
    "    \n",
    "    chipset = None  # Initialize chipset variable outside the loop\n",
    "    \n",
    "    for tbody in tbodis:\n",
    "        # Find 'Chipset' within the current tbody\n",
    "        if tbody.find_all('td', class_='attribute-name', text='Dimension'):\n",
    "            chipset = tbody.find('td', class_='attribute-value').get_text(strip=True)\n",
    "            break  # Exit the loop once chipset is found\n",
    "    \n",
    "    if chipset:\n",
    "        print(chipset)\n",
    "    else:\n",
    "        print(\"Chipset not found for this product:\", link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# productdescription = []\n",
    "\n",
    "# for link in all_links:\n",
    "#     try:\n",
    "#         # creating a path for scraping the specific information\n",
    "#         response = requests.get(link)\n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#         main = soup.find('div', class_='page-wrapper')\n",
    "#         column = main.find('div', class_='column')\n",
    "#         pro_info = column.find('div' , class_ = 'product-info-main')\n",
    "#         pro_des  = pro_info.find('div', class_ = 'product info detailed')\n",
    "\n",
    "\n",
    "#         # Find product name\n",
    "#         pro_name = soup.find('h1', class_='page-title')\n",
    "#         if pro_name:\n",
    "#             productname.append(pro_name.get_text(strip=True))\n",
    "#         else:\n",
    "#             productname.append(None)\n",
    "\n",
    "#         # Find product price\n",
    "#         pro_price = soup.find('div', class_='price-box price-final_price')\n",
    "#         if pro_price:\n",
    "#             productprice.append(pro_price.get_text(strip=True))\n",
    "#         else:\n",
    "#             productprice.append(None)\n",
    "\n",
    "#         # Find product description\n",
    "#         pro_description = soup.find('div', class_='product attribute description').find('div', class_='value')\n",
    "#         if pro_description:\n",
    "#             productdescription.append(pro_description.get_text(strip=True))\n",
    "#         else:\n",
    "#             productdescription.append(None)\n",
    "\n",
    "#         # Find product specification\n",
    "#         pro_specification = soup.find('div', class_='additional-attributes-wrapper table-wrapper').find_all('td', class_='col data')\n",
    "#         specification = [spe.get_text(strip=True) for spe in pro_specification]\n",
    "#         productspecification.append(specification)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f'Error scraping {link}: {e}')\n",
    "\n",
    "# # create a dataframe as df\n",
    "# df = pd.DataFrame({'name': productname, 'price': productprice, 'specification': productspecification, 'description': productdescription})\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
